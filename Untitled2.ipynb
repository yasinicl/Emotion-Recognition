{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44fadbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# text preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# plots and metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# preparing input to our model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# keras layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "309127f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of labels: joy, anger, fear, sadness, neutral\n",
    "num_classes = 7\n",
    "\n",
    "# Number of dimensions for word embedding\n",
    "embed_num_dims = 300\n",
    "\n",
    "# Max input length (max number of words) \n",
    "max_seq_len = 500\n",
    "\n",
    "class_names = ['joy', 'fear', 'anger', 'sadness', 'disgust', 'shame', 'guilt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e2b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('dataset/isear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "179ed265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy        1081\n",
       "fear       1081\n",
       "anger      1071\n",
       "sadness    1067\n",
       "disgust    1067\n",
       "shame      1054\n",
       "guilt      1052\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c793d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(data):\n",
    "    \n",
    "    # remove hashtags and @usernames\n",
    "    data = re.sub(r\"(#[\\d\\w\\.]+)\", '', data)\n",
    "    data = re.sub(r\"(@[\\d\\w\\.]+)\", '', data)\n",
    "    \n",
    "    # tekenization using nltk\n",
    "    data = word_tokenize(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b0b3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [' '.join(clean_text(text)) for text in data.Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "916fb024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearly caught masturbating .\n"
     ]
    }
   ],
   "source": [
    "print(texts[92])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c32175cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 8979\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "texts = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "\n",
    "# vacab size is number of unique words + reserved 0 index for padding\n",
    "vocab_size = len(index_of_words) + 1\n",
    "\n",
    "print('Number of unique words: {}'.format(len(index_of_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd45ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(text, maxlen = max_seq_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3cb8da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    2,  148,   35],\n",
       "       [   0,    0,    0, ...,    2,  784,  191],\n",
       "       [   0,    0,    0, ...,  319,   12, 2308],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   10,    3,  127],\n",
       "       [   0,    0,    0, ...,    7,  488,  862],\n",
       "       [   0,    0,    0, ...,  223,   39, 1529]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bfc59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
