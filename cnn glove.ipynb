{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "64297531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os\n",
    "#os.environ['KERAS_BACKEND']='theano' # Why theano why not\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "import neattext as nfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cbbc0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    string = re.sub(r\"\\\\\", \"\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)\n",
    "    string = re.sub(r\"\\\"\", \"\", string)\n",
    "    return string.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55248a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3b4d2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 60\n",
    "MAX_NB_WORDS = 75000\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f0e0f861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading data\n",
    "#df = pd.read_csv(\"dataset/Emotion-Stimulus.csv\")\n",
    "#df=pd.read_csv('dataset/dailydialog.csv')\n",
    "df=pd.read_csv('dataset/text_emotion.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "da3b859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['content'].apply(nfx.remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a3e8c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].apply(nfx.remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a09b62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a217adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text']=df['Text'].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "79eaa66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset  (40000, 5)\n",
      "Index(['tweet_id', 'sentiment', 'author', 'content', 'Text'], dtype='object')\n",
      "No. of unique classes 13\n"
     ]
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "print('Shape of dataset ',df.shape)\n",
    "print(df.columns)\n",
    "print('No. of unique classes',len(set(df['sentiment'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3e64ede6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d9af8d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_id  = {\"neutral\":0, \"worry\":1, \"happiness\":2, \"sadness\":3, \"love\":4, \"surprise\":5, \"fun\":6, \"relief\":7, \"hate\":8, \"empty\":9, \"enthusiasm\":10, \"boredom\":11, \"anger\":12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a8cc80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_id\"] = df['sentiment'].map(sent_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9dfdc11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>tiffanylue know listenin bad habit earlier sta...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>Layin n bed headache ughhhhwaitin</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>Funeral ceremonygloomy friday</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants hang friends SOON</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>dannycastillo want trade Houston tickets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>showMe_Heaven</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "      <td>JohnLloydTaylor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>drapeaux</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "      <td>Happy Mothers Day love</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>JenniRox</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "      <td>Happy Mothers Day mommies woman man long youre...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>ipdaman1</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "      <td>niariley WASSUP BEAUTIFUL FOLLOW PEEP NEW HIT ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>Alpharalpha</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "      <td>mopedronin bullet train tokyo gf visiting japa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment         author  \\\n",
       "0      1956967341       empty     xoshayzers   \n",
       "1      1956967666     sadness      wannamama   \n",
       "2      1956967696     sadness      coolfunky   \n",
       "3      1956967789  enthusiasm    czareaquino   \n",
       "4      1956968416     neutral      xkilljoyx   \n",
       "...           ...         ...            ...   \n",
       "39995  1753918954     neutral  showMe_Heaven   \n",
       "39996  1753919001        love       drapeaux   \n",
       "39997  1753919005        love       JenniRox   \n",
       "39998  1753919043   happiness       ipdaman1   \n",
       "39999  1753919049        love    Alpharalpha   \n",
       "\n",
       "                                                 content  \\\n",
       "0      @tiffanylue i know  i was listenin to bad habi...   \n",
       "1      Layin n bed with a headache  ughhhh...waitin o...   \n",
       "2                    Funeral ceremony...gloomy friday...   \n",
       "3                   wants to hang out with friends SOON!   \n",
       "4      @dannycastillo We want to trade with someone w...   \n",
       "...                                                  ...   \n",
       "39995                                   @JohnLloydTaylor   \n",
       "39996                     Happy Mothers Day  All my love   \n",
       "39997  Happy Mother's Day to all the mommies out ther...   \n",
       "39998  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...   \n",
       "39999  @mopedronin bullet train from tokyo    the gf ...   \n",
       "\n",
       "                                                    Text  sentiment_id  \n",
       "0      tiffanylue know listenin bad habit earlier sta...             9  \n",
       "1                      Layin n bed headache ughhhhwaitin             3  \n",
       "2                          Funeral ceremonygloomy friday             3  \n",
       "3                                wants hang friends SOON            10  \n",
       "4               dannycastillo want trade Houston tickets             0  \n",
       "...                                                  ...           ...  \n",
       "39995                                    JohnLloydTaylor             0  \n",
       "39996                             Happy Mothers Day love             4  \n",
       "39997  Happy Mothers Day mommies woman man long youre...             4  \n",
       "39998  niariley WASSUP BEAUTIFUL FOLLOW PEEP NEW HIT ...             2  \n",
       "39999  mopedronin bullet train tokyo gf visiting japa...             4  \n",
       "\n",
       "[40000 rows x 6 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6a62a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetnum=sorted(set(df['sentiment_id']))\n",
    "targetnum_to_id = dict((note, number) for number, note in enumerate(targetnum))\n",
    "\n",
    "def fun(i):\n",
    "    return targetnum_to_id[i]\n",
    "\n",
    "df['sentiment_id']=df['sentiment_id'].apply(fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d7c31eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for idx in range(df.Text.shape[0]):\n",
    "    text = BeautifulSoup(df.Text[idx])\n",
    "    texts.append(clean_str(str(text.get_text().encode())))\n",
    "\n",
    "for idx in df['sentiment_id']:\n",
    "    labels.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c60e1b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>tiffanylue know listenin bad habit earlier sta...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>Layin n bed headache ughhhhwaitin</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>Funeral ceremonygloomy friday</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants hang friends SOON</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>dannycastillo want trade Houston tickets</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habi...   \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...   \n",
       "2                Funeral ceremony...gloomy friday...   \n",
       "3               wants to hang out with friends SOON!   \n",
       "4  @dannycastillo We want to trade with someone w...   \n",
       "\n",
       "                                                Text  sentiment_id  \n",
       "0  tiffanylue know listenin bad habit earlier sta...             9  \n",
       "1                  Layin n bed headache ughhhhwaitin             3  \n",
       "2                      Funeral ceremonygloomy friday             3  \n",
       "3                            wants hang friends SOON            10  \n",
       "4           dannycastillo want trade Houston tickets             0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b1546018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Tokens 57359\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Number of Unique Tokens',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "59b3d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data Tensor: (40000, 60)\n",
      "Shape of Label Tensor: (40000, 13)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of Data Tensor:', data.shape)\n",
    "print('Shape of Label Tensor:', labels.shape)\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "19ccb3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors in Glove 6B 100d.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open('glove.6B.50d.txt',encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Total %s word vectors in Glove 6B 100d.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "07f7405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4059e002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified convolutional neural network\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 60)]              0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 60, 50)            2868000   \n",
      "                                                                 \n",
      " conv1d_34 (Conv1D)          (None, 58, 128)           19328     \n",
      "                                                                 \n",
      " max_pooling1d_32 (MaxPoolin  (None, 19, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_35 (Conv1D)          (None, 17, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_33 (MaxPoolin  (None, 5, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_36 (Conv1D)          (None, 3, 128)            49280     \n",
      "                                                                 \n",
      " max_pooling1d_34 (MaxPoolin  (None, 1, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 13)                1677      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,004,077\n",
      "Trainable params: 3,004,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_cov1= Conv1D(128, 3, activation='relu')(embedded_sequences)\n",
    "l_pool1 = MaxPooling1D(3)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 3, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(3)(l_cov2)\n",
    "l_cov3 = Conv1D(128, 3, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(3)(l_cov3)  # global max pooling\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(len(targetnum), activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"Simplified convolutional neural network\")\n",
    "model.summary()\n",
    "cp=ModelCheckpoint('model_cnn.hdf5',monitor='val_acc',verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0823df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "249/250 [============================>.] - ETA: 0s - loss: 2.1661 - acc: 0.2132\n",
      "Epoch 1: val_acc improved from -inf to 0.22000, saving model to model_cnn.hdf5\n",
      "250/250 [==============================] - 11s 41ms/step - loss: 2.1663 - acc: 0.2131 - val_loss: 2.1632 - val_acc: 0.2200\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - ETA: 0s - loss: 2.1531 - acc: 0.2154\n",
      "Epoch 2: val_acc did not improve from 0.22000\n",
      "250/250 [==============================] - 10s 41ms/step - loss: 2.1531 - acc: 0.2154 - val_loss: 2.1457 - val_acc: 0.2196\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - ETA: 0s - loss: 2.1506 - acc: 0.2113\n",
      "Epoch 3: val_acc improved from 0.22000 to 0.22013, saving model to model_cnn.hdf5\n",
      "250/250 [==============================] - 12s 49ms/step - loss: 2.1506 - acc: 0.2113 - val_loss: 2.1524 - val_acc: 0.2201\n",
      "Epoch 4/5\n",
      "249/250 [============================>.] - ETA: 0s - loss: 2.1488 - acc: 0.2139\n",
      "Epoch 4: val_acc did not improve from 0.22013\n",
      "250/250 [==============================] - 12s 50ms/step - loss: 2.1488 - acc: 0.2139 - val_loss: 2.1467 - val_acc: 0.2201\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - ETA: 0s - loss: 2.1475 - acc: 0.2171\n",
      "Epoch 5: val_acc did not improve from 0.22013\n",
      "250/250 [==============================] - 10s 40ms/step - loss: 2.1475 - acc: 0.2171 - val_loss: 2.1507 - val_acc: 0.2149\n"
     ]
    }
   ],
   "source": [
    "Cnn_1st=model.fit(x_train, y_train, validation_data=(x_val, y_val),epochs=5, batch_size=128,callbacks=[cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e2531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
